package infrastructure

import (
	"context"
	"encoding/json"
	"event-system/internal/domain"
	"fmt"
	"log"
	"time"

	"github.com/segmentio/kafka-go"
)

type KafkaPublisher struct {
	brokers  []string
	writers  map[string]*kafka.Writer // –∫—ç—à writers –¥–ª—è —Ç–æ–ø–∏–∫–æ–≤
	registry *EventRegistry
}

// NewKafkaPublisher —Å–æ–∑–¥–∞–µ—Ç publisher —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ Kafka cluster
func NewKafkaPublisher(brokers []string, registry *EventRegistry) *KafkaPublisher {
	return &KafkaPublisher{
		brokers:  brokers,
		writers:  make(map[string]*kafka.Writer),
		registry: registry,
	}
}

func (kp *KafkaPublisher) Publish(event *domain.Event) error {
	topic, _, err := kp.registry.ResolveChannel(event.Type)
	if err != nil {
		return fmt.Errorf("failed to resolve channel for event type %s: %w", event.Type, err)
	}

	writer, err := kp.getOrCreateWriter(topic)
	if err != nil {
		return fmt.Errorf("failed to get writer for topic %s: %w", topic, err)
	}

	data, err := json.Marshal(event)
	if err != nil {
		return fmt.Errorf("failed to marshal event: %w", err)
	}

	msg := kafka.Message{
		Key:   nil,
		Value: data,
		Time:  event.Timestamp,
		Headers: []kafka.Header{
			{Key: "event-type", Value: []byte(event.Type)},
		},
	}

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	if err := writer.WriteMessages(ctx, msg); err != nil {
		log.Printf("kafka publish error to topic %s: %v", topic, err)
		return fmt.Errorf("failed to publish to kafka topic %s: %w", topic, err)
	}

	log.Printf("‚úÖ Event %s published to Kafka topic: %s", event.Type, topic)
	return nil
}

// getOrCreateWriter –ø–æ–ª—É—á–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π writer –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –¥–ª—è —Ç–æ–ø–∏–∫–∞
func (kp *KafkaPublisher) getOrCreateWriter(topic string) (*kafka.Writer, error) {
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
	if writer, exists := kp.writers[topic]; exists {
		return writer, nil
	}

	// –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π writer –¥–ª—è —Ç–æ–ø–∏–∫–∞
	writer := kafka.NewWriter(kafka.WriterConfig{
		Brokers:  kp.brokers,
		Topic:    topic,
		Balancer: &kafka.LeastBytes{}, // –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –ø–∞—Ä—Ç–∏—Ü–∏—è–º
		// –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
		BatchSize:    1, // –î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ä–∞–∑—É
		BatchTimeout: 10 * time.Millisecond,
		RequiredAcks: 1,
		Async:        false,
	})

	// –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
	kp.writers[topic] = writer

	log.Printf("üìù Created new Kafka writer for topic: %s", topic)
	return writer, nil
}

// Close –∑–∞–∫—Ä—ã–≤–∞–µ—Ç –≤—Å–µ writers
func (kp *KafkaPublisher) Close() error {
	for topic, writer := range kp.writers {
		if err := writer.Close(); err != nil {
			log.Printf("error closing writer for topic %s: %v", topic, err)
		}
	}
	return nil
}

// EnsureTopicsExist —Å–æ–∑–¥–∞–µ—Ç —Ç–æ–ø–∏–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è development)
func (kp *KafkaPublisher) EnsureTopicsExist(topics []string) error {
	conn, err := kafka.Dial("tcp", kp.brokers[0])
	if err != nil {
		return err
	}
	defer conn.Close()

	for _, topic := range topics {
		topicConfigs := []kafka.TopicConfig{
			{
				Topic:             topic,
				NumPartitions:     1, // –î–ª—è –Ω–∞—á–∞–ª–∞ –æ–¥–Ω–∞ –ø–∞—Ä—Ç–∏—Ü–∏—è
				ReplicationFactor: 1, // –î–ª—è development –æ–¥–Ω–∞ —Ä–µ–ø–ª–∏–∫–∞
			},
		}

		err = conn.CreateTopics(topicConfigs...)
		if err != nil {
			log.Printf("topic %s already exists or error: %v", topic, err)
		} else {
			log.Printf("‚úÖ Created Kafka topic: %s", topic)
		}
	}
	return nil
}
